{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2\n",
    "Выполнили: Елизарова Юлия, Игошин Андрей, Кипаренко Илья, Кириленко Юлия, Клыков Вячеслав, Лепигина Анастасия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing /anaconda3/lib/python3.6/site-packages/sparkmonitor/static -> sparkmonitor\n",
      "- Validating: \u001b[32mOK\u001b[0m\n",
      "\n",
      "    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n",
      "    \n",
      "          jupyter nbextension enable sparkmonitor --user --py\n",
      "    \n",
      "Enabling notebook extension sparkmonitor/module...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "Enabling: sparkmonitor.serverextension\n",
      "- Writing config: /Users/a.y.igoshin/.jupyter\n",
      "    - Validating...\n",
      "      sparkmonitor.serverextension  \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sparkmonitor\n",
    "!jupyter nbextension install sparkmonitor --py --user --symlink \n",
    "!jupyter nbextension enable sparkmonitor --py --user            \n",
    "!jupyter serverextension enable --py --user sparkmonitor\n",
    "!ipython profile create && echo \"c.InteractiveShellApp.extensions.append('sparkmonitor.kernelextension')\" >>  $(ipython profile locate default)/ipython_kernel_config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext.getOrCreate(conf=conf) #Start the spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('MovieRatingsProject').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|           _c0|\n",
      "+--------------+\n",
      "|     943 users|\n",
      "|    1682 items|\n",
      "|100000 ratings|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = spark.read.csv('ml-100k/u.info',inferSchema=True,sep='\\t')\n",
    "info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime, year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет содержит 100 000 оценок 934 пользователями 1682 фильмов. Каждый пользователь оценил не менее 20 фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.csv('ml-100k/u.data',inferSchema=True,sep='\\t')\n",
    "ratings = ratings.withColumnRenamed('_c0','user_id').withColumnRenamed('_c1','movie_id').withColumnRenamed('_c2','rating').withColumnRenamed('_c3','timestamp')\n",
    "# ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.withColumn('year_rated', year(from_unixtime('timestamp')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+---------+----------+\n",
      "|user_id|movie_id|rating|timestamp|year_rated|\n",
      "+-------+--------+------+---------+----------+\n",
      "|    196|     242|     3|881250949|      1997|\n",
      "|    186|     302|     3|891717742|      1998|\n",
      "|     22|     377|     1|878887116|      1997|\n",
      "|    244|      51|     2|880606923|      1997|\n",
      "|    166|     346|     1|886397596|      1998|\n",
      "|    298|     474|     4|884182806|      1998|\n",
      "|    115|     265|     2|881171488|      1997|\n",
      "|    253|     465|     5|891628467|      1998|\n",
      "|    305|     451|     3|886324817|      1998|\n",
      "|      6|      86|     3|883603013|      1998|\n",
      "|     62|     257|     2|879372434|      1997|\n",
      "|    286|    1014|     5|879781125|      1997|\n",
      "|    200|     222|     5|876042340|      1997|\n",
      "|    210|      40|     3|891035994|      1998|\n",
      "|    224|      29|     3|888104457|      1998|\n",
      "|    303|     785|     3|879485318|      1997|\n",
      "|    122|     387|     5|879270459|      1997|\n",
      "|    194|     274|     2|879539794|      1997|\n",
      "|    291|    1042|     4|874834944|      1997|\n",
      "|    234|    1184|     2|892079237|      1998|\n",
      "+-------+--------+------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация о каждом фильме включает в себя название, даты выхода в прокат и появления в магазинах, ссылку на IMDB и жанр. Причем один фильм может быть отнесен к нескольким жанрам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = spark.read.csv('ml-100k/u.item', inferSchema=True, sep='|')\n",
    "names = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "for i in range(len(names)):\n",
    "    movies = movies.withColumnRenamed('_c'+str(i), names[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.withColumn('year_released', year(to_date('release_date', 'dd-MMM-yyyy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------+------------------+--------------------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+\n",
      "|movie_id|         movie_title|release_date|video_release_date|            IMDb_URL|unknown|Action|Adventure|Animation|Children's|Comedy|Crime|Documentary|Drama|Fantasy|Film-Noir|Horror|Musical|Mystery|Romance|Sci-Fi|Thriller|War|Western|year_released|\n",
      "+--------+--------------------+------------+------------------+--------------------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+\n",
      "|       1|    Toy Story (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        1|         1|     1|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1995|\n",
      "|       2|    GoldenEye (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|         1995|\n",
      "|       3|   Four Rooms (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|         1995|\n",
      "|       4|   Get Shorty (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     1|        0|        0|         0|     1|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1995|\n",
      "|       5|      Copycat (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    1|          0|    1|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|         1995|\n",
      "|       6|Shanghai Triad (Y...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1995|\n",
      "|       7|Twelve Monkeys (1...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     1|       0|  0|      0|         1995|\n",
      "|       8|         Babe (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         1|     1|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1995|\n",
      "|       9|Dead Man Walking ...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1995|\n",
      "|      10|  Richard III (1995)| 22-Jan-1996|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  1|      0|         1996|\n",
      "|      11|Seven (Se7en) (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    1|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|         1995|\n",
      "|      12|Usual Suspects, T...| 14-Aug-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    1|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|         1995|\n",
      "|      13|Mighty Aphrodite ...| 30-Oct-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     1|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1995|\n",
      "|      14|  Postino, Il (1994)| 01-Jan-1994|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      1|     0|       0|  0|      0|         1994|\n",
      "|      15|Mr. Holland's Opu...| 29-Jan-1996|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|\n",
      "|      16|French Twist (Gaz...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     1|    0|          0|    0|      0|        0|     0|      0|      0|      1|     0|       0|  0|      0|         1995|\n",
      "|      17|From Dusk Till Da...| 05-Feb-1996|              null|http://us.imdb.co...|      0|     1|        0|        0|         0|     1|    1|          0|    0|      0|        0|     1|      0|      0|      0|     0|       1|  0|      0|         1996|\n",
      "|      18|White Balloon, Th...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1995|\n",
      "|      19|Antonia's Line (1...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1995|\n",
      "|      20|Angels and Insect...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      1|     0|       0|  0|      0|         1995|\n",
      "+--------+--------------------+------------+------------------+--------------------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация о каждом пользователе включает в себя возраст, пол, профессию и почтовый индекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+--------+\n",
      "|user_id|age|gender|   occupation|zip_code|\n",
      "+-------+---+------+-------------+--------+\n",
      "|      1| 24|     M|   technician|   85711|\n",
      "|      2| 53|     F|        other|   94043|\n",
      "|      3| 23|     M|       writer|   32067|\n",
      "|      4| 24|     M|   technician|   43537|\n",
      "|      5| 33|     F|        other|   15213|\n",
      "|      6| 42|     M|    executive|   98101|\n",
      "|      7| 57|     M|administrator|   91344|\n",
      "|      8| 36|     M|administrator|   05201|\n",
      "|      9| 29|     M|      student|   01002|\n",
      "|     10| 53|     M|       lawyer|   90703|\n",
      "|     11| 39|     F|        other|   30329|\n",
      "|     12| 28|     F|        other|   06405|\n",
      "|     13| 47|     M|     educator|   29206|\n",
      "|     14| 45|     M|    scientist|   55106|\n",
      "|     15| 49|     F|     educator|   97301|\n",
      "|     16| 21|     M|entertainment|   10309|\n",
      "|     17| 30|     M|   programmer|   06355|\n",
      "|     18| 35|     F|        other|   37212|\n",
      "|     19| 40|     M|    librarian|   02138|\n",
      "|     20| 42|     F|    homemaker|   95660|\n",
      "+-------+---+------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = spark.read.csv('ml-100k/u.user', inferSchema=True, sep='|')\n",
    "names = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "for i in range(len(names)):\n",
    "    users = users.withColumnRenamed('_c'+str(i), names[i])\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"gender\", outputCol=\"indexed_gender\", handleInvalid='error')\n",
    "model = stringIndexer.fit(users)\n",
    "users = model.transform(users)\n",
    "encoder = OneHotEncoder(inputCol=\"indexed_gender\", outputCol='gender_feature')\n",
    "users = encoder.transform(users)\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"occupation\", outputCol=\"indexed_occupation\", handleInvalid='error')\n",
    "model = stringIndexer.fit(users)\n",
    "users = model.transform(users)\n",
    "encoder = OneHotEncoder(inputCol=\"indexed_occupation\", outputCol='occupation_feature')\n",
    "users = encoder.transform(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+--------+\n",
      "|user_id|age|gender|   occupation|zip_code|\n",
      "+-------+---+------+-------------+--------+\n",
      "|      1| 24|     M|   technician|   85711|\n",
      "|      2| 53|     F|        other|   94043|\n",
      "|      3| 23|     M|       writer|   32067|\n",
      "|      4| 24|     M|   technician|   43537|\n",
      "|      5| 33|     F|        other|   15213|\n",
      "|      6| 42|     M|    executive|   98101|\n",
      "|      7| 57|     M|administrator|   91344|\n",
      "|      8| 36|     M|administrator|   05201|\n",
      "|      9| 29|     M|      student|   01002|\n",
      "|     10| 53|     M|       lawyer|   90703|\n",
      "|     11| 39|     F|        other|   30329|\n",
      "|     12| 28|     F|        other|   06405|\n",
      "|     13| 47|     M|     educator|   29206|\n",
      "|     14| 45|     M|    scientist|   55106|\n",
      "|     15| 49|     F|     educator|   97301|\n",
      "|     16| 21|     M|entertainment|   10309|\n",
      "|     17| 30|     M|   programmer|   06355|\n",
      "|     18| 35|     F|        other|   37212|\n",
      "|     19| 40|     M|    librarian|   02138|\n",
      "|     20| 42|     F|    homemaker|   95660|\n",
      "+-------+---+------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения целостного датасета было принято решение собрать датафреймы с оценками и информацией о фильмах и пользователях в один."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joined_df = ratings.join(users, [\"user_id\"], 'outer').drop('zip_code', 'timestamp')\n",
    "joined_df = joined_df.join(movies, [\"movie_id\"], 'outer').drop('movie_title', 'release_date', 'video_release_date', 'IMDb_URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.withColumn('rated_released_year_diff', joined_df.year_rated - joined_df.year_released)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------+----------+---+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+------------------------+\n",
      "|movie_id|user_id|rating|year_rated|age|gender|occupation|unknown|Action|Adventure|Animation|Children's|Comedy|Crime|Documentary|Drama|Fantasy|Film-Noir|Horror|Musical|Mystery|Romance|Sci-Fi|Thriller|War|Western|year_released|rated_released_year_diff|\n",
      "+--------+-------+------+----------+---+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+------------------------+\n",
      "|     148|    251|     2|      1998| 28|     M|    doctor|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    580|     4|      1998| 16|     M|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    633|     1|      1997| 35|     M|programmer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    642|     5|      1998| 18|     F|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    406|     3|      1997| 52|     M|  educator|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|     26|     3|      1998| 49|     M|  engineer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|     27|     3|      1998| 40|     F| librarian|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    332|     5|      1998| 20|     M|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|     44|     4|      1997| 26|     M|technician|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    271|     3|      1998| 51|     M|  engineer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    606|     3|      1997| 28|     M|programmer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    916|     2|      1997| 27|     M|  engineer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    236|     4|      1998| 44|     F|    writer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    602|     4|      1998| 47|     F|     other|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    663|     4|      1998| 26|     M|     other|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    222|     2|      1997| 29|     M|programmer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    601|     3|      1997| 19|     F|    artist|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    330|     4|      1997| 35|     F|  educator|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    372|     5|      1997| 25|     F|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    727|     2|      1998| 25|     M|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "+--------+-------+------+----------+---+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категориальные значения (профессия, пол) были оформлены при помощи one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------+----------+---+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+------------------------+\n",
      "|movie_id|user_id|rating|year_rated|age|gender|occupation|unknown|Action|Adventure|Animation|Children's|Comedy|Crime|Documentary|Drama|Fantasy|Film-Noir|Horror|Musical|Mystery|Romance|Sci-Fi|Thriller|War|Western|year_released|rated_released_year_diff|\n",
      "+--------+-------+------+----------+---+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+------------------------+\n",
      "|     148|    251|     2|      1998| 28|     M|    doctor|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    580|     4|      1998| 16|     M|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    633|     1|      1997| 35|     M|programmer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    642|     5|      1998| 18|     F|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    406|     3|      1997| 52|     M|  educator|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|     26|     3|      1998| 49|     M|  engineer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|     27|     3|      1998| 40|     F| librarian|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    332|     5|      1998| 20|     M|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|     44|     4|      1997| 26|     M|technician|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    271|     3|      1998| 51|     M|  engineer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    606|     3|      1997| 28|     M|programmer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    916|     2|      1997| 27|     M|  engineer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    236|     4|      1998| 44|     F|    writer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    602|     4|      1998| 47|     F|     other|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    663|     4|      1998| 26|     M|     other|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "|     148|    222|     2|      1997| 29|     M|programmer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    601|     3|      1997| 19|     F|    artist|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    330|     4|      1997| 35|     F|  educator|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    372|     5|      1997| 25|     F|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|\n",
      "|     148|    727|     2|      1998| 25|     M|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       2|\n",
      "+--------+-------+------+----------+---+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# mmScaler = MinMaxScaler(inputCol=\"age\", outputCol=\"scaled_age\")\n",
    "# model = mmScaler.fit(joined_df)\n",
    "# model.transform(joined_df)\n",
    "\n",
    "# joined_df = joined_df.drop(\"user_id\", \"movie_id\", \"gender\", \"indexed_gender\", \"occupation\", \"indexed_occupation\", \"age\")\n",
    "# joined_df.show()\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+\n",
      "|user_id|avg(unknown)|       avg(Action)|    avg(Adventure)|    avg(Animation)|   avg(Children's)|       avg(Comedy)|        avg(Crime)|  avg(Documentary)|        avg(Drama)|avg(Fantasy)|   avg(Film-Noir)|       avg(Horror)|      avg(Musical)|      avg(Mystery)|      avg(Romance)|       avg(Sci-Fi)|     avg(Thriller)|          avg(War)|avg(Western)|\n",
      "+-------+------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+\n",
      "|    148|         0.0|3.9166666666666665| 3.933333333333333| 4.428571428571429|               3.8|              4.45|3.6666666666666665|               0.0|              3.68|         0.0|              5.0|               2.0| 4.454545454545454|               3.0| 4.333333333333333| 4.461538461538462|               3.6|               4.1|         2.0|\n",
      "|    463|         0.0| 2.761904761904762|               2.4|               2.2|2.0588235294117645|              2.46|               3.5|               4.0| 3.406779661016949|         2.5|              5.0|               1.0|1.8571428571428572| 4.666666666666667|3.2857142857142856|3.3333333333333335|2.7058823529411766|2.5555555555555554|         0.0|\n",
      "|    471|         0.0|               4.0| 3.857142857142857|            2.6875|3.3461538461538463| 4.416666666666667|               0.0|               0.0|3.3333333333333335|         0.0|              0.0|               0.0| 2.111111111111111|               4.0|               4.0|               4.0|               0.0|               3.5|         0.0|\n",
      "|    496|         0.0|           3.09375|2.7916666666666665|             3.125| 2.380952380952381|              2.75|3.6666666666666665|               0.0|3.2115384615384617|         3.0|              4.0|3.3333333333333335|2.6666666666666665|2.7142857142857144|3.6818181818181817|              3.12|               2.8|              4.25|         2.0|\n",
      "|    833|         1.0| 2.736111111111111| 2.533333333333333|               4.0|               4.0| 2.753846153846154|3.3714285714285714|               4.0|3.3092783505154637|         3.0|4.111111111111111|               3.0|               2.4|               3.1|2.6153846153846154|2.8085106382978724|2.9722222222222223|3.3181818181818183|         4.0|\n",
      "|    243|         0.0|3.6666666666666665|              3.75|               4.0|3.6666666666666665|3.5555555555555554|3.3333333333333335|               4.0|3.6271186440677967|         3.0|              0.0|               4.0|               0.0|               5.0| 3.423076923076923|               3.0|              3.25|               4.0|         4.0|\n",
      "|    392|         0.0|               3.6| 4.166666666666667|               3.8|               4.0| 4.071428571428571|4.2727272727272725|               4.0| 4.298245614035087|         0.0|4.666666666666667|               3.5|               4.5|3.5555555555555554|               4.0|3.3636363636363638| 3.736842105263158| 4.090909090909091|         4.0|\n",
      "|    540|         0.0|3.6842105263157894|             3.875|               3.2|              3.25|             3.625|               4.0|               0.0|3.7857142857142856|         3.0|              0.0|               4.0|               3.5|               3.5|3.8181818181818183|3.9166666666666665|             3.625| 3.857142857142857|         0.0|\n",
      "|    623|         0.0|               4.0| 4.333333333333333|               0.0|               0.0| 3.789473684210526|              3.75|               0.0|3.5833333333333335|         0.0|              3.5|               3.0|3.3333333333333335|               4.0| 3.823529411764706|               3.9|             3.375|               4.0|         5.0|\n",
      "|    737|         0.0|              3.75|               3.0|               2.5|               1.0|               4.0|               4.5|               4.0|              4.25|         0.0|              4.0|               0.0|               3.0|               0.0|               4.0|               4.0|               3.8| 4.333333333333333|         0.0|\n",
      "|    858|         0.0|3.6666666666666665|               2.5|               0.0|               0.0|               4.0|3.5714285714285716|               0.0|3.4166666666666665|         0.0|              0.0|               3.0|               3.0|               3.5|               3.0|               2.0|             3.125|              3.25|         0.0|\n",
      "|    897|         0.0| 4.192982456140351| 4.085714285714285| 4.181818181818182| 4.038461538461538| 3.767857142857143|3.4166666666666665|               0.0| 3.890909090909091|         4.4|              4.0| 4.571428571428571|               4.2| 4.166666666666667|            3.9375| 4.178571428571429|              3.95|              4.25|         4.0|\n",
      "|     31|         0.0|               3.4|               4.0|               0.0|               0.0|               4.2|              4.25| 4.666666666666667|3.8461538461538463|         0.0|             4.25|               2.0|               4.5|3.6666666666666665|               3.6| 4.333333333333333| 3.111111111111111|               4.0|         0.0|\n",
      "|    516|         0.0|               4.0|               4.0|               5.0|               0.0|               4.2| 4.333333333333333|               0.0|3.9166666666666665|         0.0|              0.0|               0.0|               3.0|               4.5|              4.75|               4.4|               5.0| 4.142857142857143|         0.0|\n",
      "|     85|         0.0|3.4130434782608696|              3.25|               3.6|3.5217391304347827|3.5402298850574714|3.8181818181818183|               3.5|3.5526315789473686|         3.5|              4.0|               4.0|3.7916666666666665|               3.5| 3.769230769230769|3.6538461538461537| 3.310344827586207| 3.757575757575758|       3.375|\n",
      "|    137|         0.0| 4.857142857142857| 4.928571428571429|               3.0|              3.75|               4.0|               4.5|               0.0|3.3333333333333335|         4.0|              5.0|               5.0|               3.0|               4.0|4.2727272727272725| 4.857142857142857| 4.785714285714286|               4.0|         1.0|\n",
      "|    251|         0.0|3.7419354838709675| 3.764705882352941|3.6666666666666665|               4.2|              3.75|               3.6|               3.0| 4.130434782608695|         3.0|              0.0| 4.666666666666667|               4.0|               2.5|              3.75|3.9285714285714284| 3.769230769230769| 4.428571428571429|         0.0|\n",
      "|    451|         0.0| 3.176470588235294|2.5714285714285716|               1.0|              2.25|2.6538461538461537|               3.0|2.6666666666666665| 2.473684210526316|         1.0|              2.0|               3.0|1.3333333333333333|3.8181818181818183| 2.823529411764706|               3.4| 3.586206896551724|2.8333333333333335|         0.0|\n",
      "|    580|         0.0|3.4545454545454546|3.8181818181818183|               3.0|               2.5|3.5833333333333335|               3.0|               0.0|3.5833333333333335|         0.0|              0.0| 4.666666666666667|               5.0|               2.0|3.7142857142857144| 4.461538461538462|            3.0625| 4.142857142857143|         0.0|\n",
      "|    808|         0.0|3.8333333333333335|               3.0|               0.0|               0.0|               4.0|               4.4|               0.0| 4.153846153846154|         0.0|              5.0|               3.0|               0.0|              4.25| 4.166666666666667|               4.0| 3.727272727272727|3.6666666666666665|         0.0|\n",
      "+-------+------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_ratings_df = joined_df.select(['user_id', 'rating']  + genres)\n",
    "\n",
    "for genre in genres:\n",
    "    avg_ratings_df = avg_ratings_df.withColumn('rating {}'.format(genre), avg_ratings_df[genre] * avg_ratings_df.rating)\n",
    "\n",
    "genre_ratings = list(map(lambda genre: 'rating {}'.format(genre), genres))\n",
    "df1 = avg_ratings_df.groupBy('user_id').sum(*genres)\n",
    "df2 = avg_ratings_df.groupBy('user_id').sum(*genre_ratings)\n",
    "\n",
    "avg_ratings_df = df1.join(df2, ['user_id'])\n",
    "for genre in genres:\n",
    "    sum_rating_col = 'sum(rating {})'.format(genre)\n",
    "    count_col = 'sum({})'.format(genre)\n",
    "    avg_ratings_df = avg_ratings_df.withColumn('avg({})'\n",
    "                                   .format(genre), avg_ratings_df[sum_rating_col] / avg_ratings_df[count_col])\n",
    "    avg_ratings_df = avg_ratings_df.drop(sum_rating_col, count_col)\n",
    "\n",
    "avg_ratings_df = avg_ratings_df.fillna(value=0)\n",
    "avg_ratings_df.show()\n",
    "avg_ratings_df.toPandas().to_csv('~/avg_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+------------------+\n",
      "|movie_id|avg(movie_id)|       avg(rating)|\n",
      "+--------+-------------+------------------+\n",
      "|     496|        496.0| 4.121212121212121|\n",
      "|     471|        471.0|3.6108597285067874|\n",
      "|     463|        463.0| 3.859154929577465|\n",
      "|     148|        148.0|          3.203125|\n",
      "|    1342|       1342.0|               2.5|\n",
      "|     833|        833.0| 3.204081632653061|\n",
      "|    1088|       1088.0| 2.230769230769231|\n",
      "|    1591|       1591.0|3.1666666666666665|\n",
      "|    1238|       1238.0|             3.125|\n",
      "|    1580|       1580.0|               1.0|\n",
      "|    1645|       1645.0|               4.0|\n",
      "|     392|        392.0|3.5441176470588234|\n",
      "|     623|        623.0| 2.923076923076923|\n",
      "|     540|        540.0| 2.511627906976744|\n",
      "|     858|        858.0|               1.0|\n",
      "|     737|        737.0| 2.983050847457627|\n",
      "|     243|        243.0|2.4393939393939394|\n",
      "|    1025|       1025.0|2.9318181818181817|\n",
      "|    1084|       1084.0| 3.857142857142857|\n",
      "|    1127|       1127.0| 2.909090909090909|\n",
      "+--------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_movie_rating = ratings.select('movie_id', 'rating')\n",
    "average_movie_rating = average_movie_rating.groupBy('movie_id').avg()\n",
    "\n",
    "average_movie_rating.toPandas().to_csv('~/average_movie_rating.csv')\n",
    "average_movie_rating.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|movie_id|count|\n",
      "+--------+-----+\n",
      "|     496|  231|\n",
      "|     471|  221|\n",
      "|     463|   71|\n",
      "|     148|  128|\n",
      "|    1342|    2|\n",
      "|     833|   49|\n",
      "|    1088|   13|\n",
      "|    1591|    6|\n",
      "|    1238|    8|\n",
      "|    1580|    1|\n",
      "|    1645|    1|\n",
      "|     392|   68|\n",
      "|     623|   39|\n",
      "|     540|   43|\n",
      "|     858|    3|\n",
      "|     737|   59|\n",
      "|     243|  132|\n",
      "|    1025|   44|\n",
      "|    1084|   21|\n",
      "|    1127|   11|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popularity = ratings.select('movie_id')\n",
    "popularity = popularity.groupBy('movie_id').count()\n",
    "\n",
    "popularity.toPandas().to_csv('~/movie_popularity.csv')\n",
    "popularity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.join(average_movie_rating, 'movie_id')\n",
    "# joined_df.join(popularity, ['movie_id'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.mllib.stat import Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+------------------------+-------------+------------------+------------+------------------+-----------------+-----------------+---------------+-----------+------------------+----------------+----------+------------+--------------+-----------+-----------------+------------+-----------------+-----------------+-------------+--------+------------+\n",
      "|rating|year_rated|unknown|Action|Adventure|Animation|Children's|Comedy|Crime|Documentary|Drama|Fantasy|Film-Noir|Horror|Musical|Mystery|Romance|Sci-Fi|Thriller|War|Western|year_released|rated_released_year_diff|avg(movie_id)|       avg(rating)|avg(unknown)|       avg(Action)|   avg(Adventure)|   avg(Animation)|avg(Children's)|avg(Comedy)|        avg(Crime)|avg(Documentary)|avg(Drama)|avg(Fantasy)|avg(Film-Noir)|avg(Horror)|     avg(Musical)|avg(Mystery)|     avg(Romance)|      avg(Sci-Fi)|avg(Thriller)|avg(War)|avg(Western)|\n",
      "+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+------------------------+-------------+------------------+------------+------------------+-----------------+-----------------+---------------+-----------+------------------+----------------+----------+------------+--------------+-----------+-----------------+------------+-----------------+-----------------+-------------+--------+------------+\n",
      "|     5|      1997|      0|     0|        0|        1|         0|     1|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|         1996|                       1|        408.0| 4.491071428571429|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     4|      1997|      0|     0|        0|        1|         1|     1|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1995|                       2|          1.0|3.8783185840707963|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     1|      1997|      0|     0|        1|        0|         1|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1993|                       4|        140.0|3.2131147540983607|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     5|      1997|      0|     0|        0|        1|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1996|                       1|        114.0| 4.447761194029851|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     5|      1997|      0|     0|        0|        0|         0|     1|    0|          0|    0|      0|        0|     0|      0|      0|      1|     0|       0|  0|      0|         1994|                       3|         70.0|3.6613545816733066|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     4|      1997|      0|     0|        1|        0|         0|     1|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1956|                      41|        495.0|3.6610169491525424|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     5|      1997|      0|     1|        1|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      1|     1|       0|  1|      0|         1980|                      17|        172.0| 4.204359673024523|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     5|      1997|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1971|                      26|       1149.0|3.8461538461538463|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     2|      1997|      0|     1|        0|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      1|         1966|                      31|        177.0|3.8613138686131387|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     1|      1997|      0|     0|        0|        0|         0|     0|    0|          0|    0|      0|        0|     1|      0|      0|      1|     0|       1|  0|      0|         1960|                      37|        185.0| 4.100418410041841|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     4|      1997|      0|     0|        0|        1|         1|     0|    0|          0|    0|      0|        0|     0|      1|      0|      0|     0|       0|  0|      0|         1941|                      56|        501.0|3.4959349593495936|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     5|      1997|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1985|                      12|        529.0| 3.978494623655914|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     3|      1997|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|         1991|                       6|         98.0|  4.28974358974359|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     5|      1997|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      1|      0|      0|     0|       0|  1|      0|         1982|                      15|        214.0|3.3508771929824563|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     5|      1997|      0|     0|        0|        1|         1|     0|    0|          0|    0|      0|        0|     0|      1|      0|      0|     0|       0|  0|      0|         1996|                       1|        596.0| 3.377952755905512|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     5|      1997|      0|     0|        0|        1|         1|     0|    0|          0|    0|      0|        0|     0|      1|      0|      0|     0|       0|  0|      0|         1994|                       3|         71.0|3.7818181818181817|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     4|      1997|      0|     0|        0|        0|         0|     1|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1997|                       0|       1012.0|              3.53|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     4|      1997|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     1|       0|  0|      0|         1982|                      15|        228.0|3.8155737704918034|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     5|      1997|      0|     0|        0|        1|         1|     0|    0|          0|    0|      0|        0|     0|      1|      0|      0|     0|       0|  0|      0|         1996|                       1|        473.0| 3.126984126984127|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "|     5|      1997|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|         1975|                      22|        357.0| 4.291666666666667|         0.0|3.9166666666666665|3.933333333333333|4.428571428571429|            3.8|       4.45|3.6666666666666665|             0.0|      3.68|         0.0|           5.0|        2.0|4.454545454545454|         3.0|4.333333333333333|4.461538461538462|          3.6|     4.1|         2.0|\n",
      "+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+-------------+------------------------+-------------+------------------+------------+------------------+-----------------+-----------------+---------------+-----------+------------------+----------------+----------+------------+--------------+-----------+-----------------+------------+-----------------+-----------------+-------------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = joined_df.join(avg_ratings_df, ['user_id'])\n",
    "final_df = joined_df.drop(\"user_id\", \"movie_id\", \"gender\", \"indexed_gender\", \"occupation\", \"indexed_occupation\", \"age\")\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year_rated', 'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western', 'year_released', 'rated_released_year_diff', 'avg(movie_id)', 'avg(rating)', 'avg(unknown)', 'avg(Action)', 'avg(Adventure)', 'avg(Animation)', \"avg(Children's)\", 'avg(Comedy)', 'avg(Crime)', 'avg(Documentary)', 'avg(Drama)', 'avg(Fantasy)', 'avg(Film-Noir)', 'avg(Horror)', 'avg(Musical)', 'avg(Mystery)', 'avg(Romance)', 'avg(Sci-Fi)', 'avg(Thriller)', 'avg(War)', 'avg(Western)']\n"
     ]
    }
   ],
   "source": [
    "answer_col = 'rating'\n",
    "features_col = 'features'\n",
    "input_cols = [col for col in final_df.columns if col != answer_col]\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=features_col)\n",
    "\n",
    "print(input_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|rating|features                                                                                                                                                                                                                                                                                                                      |\n",
      "+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|5     |(43,[0,4,6,17,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1.0,1996.0,1.0,408.0,4.491071428571429,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                     |\n",
      "|4     |(43,[0,4,5,6,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1.0,1995.0,2.0,1.0,3.8783185840707963,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                       |\n",
      "|1     |(43,[0,3,5,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1993.0,4.0,140.0,3.2131147540983607,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                           |\n",
      "|5     |(43,[0,4,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1996.0,1.0,114.0,4.447761194029851,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                                  |\n",
      "|5     |(43,[0,6,15,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1994.0,3.0,70.0,3.6613545816733066,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                           |\n",
      "|4     |(43,[0,3,6,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1956.0,41.0,495.0,3.6610169491525424,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                          |\n",
      "|5     |(43,[0,2,3,9,15,16,18,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1.0,1.0,1.0,1.0,1980.0,17.0,172.0,4.204359673024523,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])|\n",
      "|5     |(43,[0,9,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1971.0,26.0,1149.0,3.8461538461538463,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                               |\n",
      "|2     |(43,[0,2,19,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1966.0,31.0,177.0,3.8613138686131387,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                         |\n",
      "|1     |(43,[0,12,15,17,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1.0,1960.0,37.0,185.0,4.100418410041841,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                  |\n",
      "|4     |(43,[0,4,5,13,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1.0,1941.0,56.0,501.0,3.4959349593495936,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                   |\n",
      "|5     |(43,[0,9,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1985.0,12.0,529.0,3.978494623655914,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                                 |\n",
      "|3     |(43,[0,9,17,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1991.0,6.0,98.0,4.28974358974359,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                             |\n",
      "|5     |(43,[0,9,13,18,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1.0,1982.0,15.0,214.0,3.3508771929824563,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                  |\n",
      "|5     |(43,[0,4,5,13,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1.0,1996.0,1.0,596.0,3.377952755905512,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                     |\n",
      "|5     |(43,[0,4,5,13,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1.0,1994.0,3.0,71.0,3.7818181818181817,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                     |\n",
      "|4     |(43,[0,6,9,20,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1997.0,1012.0,3.53,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                                               |\n",
      "|4     |(43,[0,2,3,16,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1.0,1982.0,15.0,228.0,3.8155737704918034,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                   |\n",
      "|5     |(43,[0,4,5,13,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1.0,1.0,1996.0,1.0,473.0,3.126984126984127,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                     |\n",
      "|5     |(43,[0,9,20,21,22,23,25,26,27,28,29,30,32,34,35,36,37,38,39,40,41,42],[1997.0,1.0,1975.0,22.0,357.0,4.291666666666667,3.9166666666666665,3.933333333333333,4.428571428571429,3.8,4.45,3.6666666666666665,3.68,5.0,2.0,4.454545454545454,3.0,4.333333333333333,4.461538461538462,3.6,4.1,2.0])                                 |\n",
      "+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = assembler.transform(final_df)\n",
    "data = data.select(answer_col,features_col)\n",
    "data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(labelCol=answer_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o466.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 97.0 failed 1 times, most recent failure: Lost task 0.0 in stage 97.0 (TID 5070, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$4: (struct<year_rated_double_VectorAssembler_f91bcc66438c:double,unknown_double_VectorAssembler_f91bcc66438c:double,Action_double_VectorAssembler_f91bcc66438c:double,Adventure_double_VectorAssembler_f91bcc66438c:double,Animation_double_VectorAssembler_f91bcc66438c:double,Children's_double_VectorAssembler_f91bcc66438c:double,Comedy_double_VectorAssembler_f91bcc66438c:double,Crime_double_VectorAssembler_f91bcc66438c:double,Documentary_double_VectorAssembler_f91bcc66438c:double,Drama_double_VectorAssembler_f91bcc66438c:double,Fantasy_double_VectorAssembler_f91bcc66438c:double,Film-Noir_double_VectorAssembler_f91bcc66438c:double,Horror_double_VectorAssembler_f91bcc66438c:double,Musical_double_VectorAssembler_f91bcc66438c:double,Mystery_double_VectorAssembler_f91bcc66438c:double,Romance_double_VectorAssembler_f91bcc66438c:double,Sci-Fi_double_VectorAssembler_f91bcc66438c:double,Thriller_double_VectorAssembler_f91bcc66438c:double,War_double_VectorAssembler_f91bcc66438c:double,Western_double_VectorAssembler_f91bcc66438c:double,year_released_double_VectorAssembler_f91bcc66438c:double,rated_released_year_diff_double_VectorAssembler_f91bcc66438c:double,avg(movie_id):double,avg(rating):double,avg(unknown):double,avg(Action):double,avg(Adventure):double,avg(Animation):double,avg(Children's):double,avg(Comedy):double,avg(Crime):double,avg(Documentary):double,avg(Drama):double,avg(Fantasy):double,avg(Film-Noir):double,avg(Horror):double,avg(Musical):double,avg(Mystery):double,avg(Romance):double,avg(Sci-Fi):double,avg(Thriller):double,avg(War):double,avg(Western):double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage26.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage26.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$2.hasNext(WholeStageCodegenExec.scala:638)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:390)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"keep\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:287)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:255)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:255)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:144)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:143)\n\t... 32 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1337)\n\tat org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:112)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:106)\n\tat org.apache.spark.ml.regression.RandomForestRegressor$$anonfun$train$1.apply(RandomForestRegressor.scala:133)\n\tat org.apache.spark.ml.regression.RandomForestRegressor$$anonfun$train$1.apply(RandomForestRegressor.scala:119)\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:183)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:183)\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:119)\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:46)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$4: (struct<year_rated_double_VectorAssembler_f91bcc66438c:double,unknown_double_VectorAssembler_f91bcc66438c:double,Action_double_VectorAssembler_f91bcc66438c:double,Adventure_double_VectorAssembler_f91bcc66438c:double,Animation_double_VectorAssembler_f91bcc66438c:double,Children's_double_VectorAssembler_f91bcc66438c:double,Comedy_double_VectorAssembler_f91bcc66438c:double,Crime_double_VectorAssembler_f91bcc66438c:double,Documentary_double_VectorAssembler_f91bcc66438c:double,Drama_double_VectorAssembler_f91bcc66438c:double,Fantasy_double_VectorAssembler_f91bcc66438c:double,Film-Noir_double_VectorAssembler_f91bcc66438c:double,Horror_double_VectorAssembler_f91bcc66438c:double,Musical_double_VectorAssembler_f91bcc66438c:double,Mystery_double_VectorAssembler_f91bcc66438c:double,Romance_double_VectorAssembler_f91bcc66438c:double,Sci-Fi_double_VectorAssembler_f91bcc66438c:double,Thriller_double_VectorAssembler_f91bcc66438c:double,War_double_VectorAssembler_f91bcc66438c:double,Western_double_VectorAssembler_f91bcc66438c:double,year_released_double_VectorAssembler_f91bcc66438c:double,rated_released_year_diff_double_VectorAssembler_f91bcc66438c:double,avg(movie_id):double,avg(rating):double,avg(unknown):double,avg(Action):double,avg(Adventure):double,avg(Animation):double,avg(Children's):double,avg(Comedy):double,avg(Crime):double,avg(Documentary):double,avg(Drama):double,avg(Fantasy):double,avg(Film-Noir):double,avg(Horror):double,avg(Musical):double,avg(Mystery):double,avg(Romance):double,avg(Sci-Fi):double,avg(Thriller):double,avg(War):double,avg(Western):double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage26.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage26.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$2.hasNext(WholeStageCodegenExec.scala:638)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:390)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"keep\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:287)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:255)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:255)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:144)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:143)\n\t... 32 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-868b577c10fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o466.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 97.0 failed 1 times, most recent failure: Lost task 0.0 in stage 97.0 (TID 5070, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$4: (struct<year_rated_double_VectorAssembler_f91bcc66438c:double,unknown_double_VectorAssembler_f91bcc66438c:double,Action_double_VectorAssembler_f91bcc66438c:double,Adventure_double_VectorAssembler_f91bcc66438c:double,Animation_double_VectorAssembler_f91bcc66438c:double,Children's_double_VectorAssembler_f91bcc66438c:double,Comedy_double_VectorAssembler_f91bcc66438c:double,Crime_double_VectorAssembler_f91bcc66438c:double,Documentary_double_VectorAssembler_f91bcc66438c:double,Drama_double_VectorAssembler_f91bcc66438c:double,Fantasy_double_VectorAssembler_f91bcc66438c:double,Film-Noir_double_VectorAssembler_f91bcc66438c:double,Horror_double_VectorAssembler_f91bcc66438c:double,Musical_double_VectorAssembler_f91bcc66438c:double,Mystery_double_VectorAssembler_f91bcc66438c:double,Romance_double_VectorAssembler_f91bcc66438c:double,Sci-Fi_double_VectorAssembler_f91bcc66438c:double,Thriller_double_VectorAssembler_f91bcc66438c:double,War_double_VectorAssembler_f91bcc66438c:double,Western_double_VectorAssembler_f91bcc66438c:double,year_released_double_VectorAssembler_f91bcc66438c:double,rated_released_year_diff_double_VectorAssembler_f91bcc66438c:double,avg(movie_id):double,avg(rating):double,avg(unknown):double,avg(Action):double,avg(Adventure):double,avg(Animation):double,avg(Children's):double,avg(Comedy):double,avg(Crime):double,avg(Documentary):double,avg(Drama):double,avg(Fantasy):double,avg(Film-Noir):double,avg(Horror):double,avg(Musical):double,avg(Mystery):double,avg(Romance):double,avg(Sci-Fi):double,avg(Thriller):double,avg(War):double,avg(Western):double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage26.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage26.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$2.hasNext(WholeStageCodegenExec.scala:638)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:390)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"keep\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:287)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:255)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:255)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:144)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:143)\n\t... 32 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1337)\n\tat org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:112)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:106)\n\tat org.apache.spark.ml.regression.RandomForestRegressor$$anonfun$train$1.apply(RandomForestRegressor.scala:133)\n\tat org.apache.spark.ml.regression.RandomForestRegressor$$anonfun$train$1.apply(RandomForestRegressor.scala:119)\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:183)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:183)\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:119)\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:46)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$4: (struct<year_rated_double_VectorAssembler_f91bcc66438c:double,unknown_double_VectorAssembler_f91bcc66438c:double,Action_double_VectorAssembler_f91bcc66438c:double,Adventure_double_VectorAssembler_f91bcc66438c:double,Animation_double_VectorAssembler_f91bcc66438c:double,Children's_double_VectorAssembler_f91bcc66438c:double,Comedy_double_VectorAssembler_f91bcc66438c:double,Crime_double_VectorAssembler_f91bcc66438c:double,Documentary_double_VectorAssembler_f91bcc66438c:double,Drama_double_VectorAssembler_f91bcc66438c:double,Fantasy_double_VectorAssembler_f91bcc66438c:double,Film-Noir_double_VectorAssembler_f91bcc66438c:double,Horror_double_VectorAssembler_f91bcc66438c:double,Musical_double_VectorAssembler_f91bcc66438c:double,Mystery_double_VectorAssembler_f91bcc66438c:double,Romance_double_VectorAssembler_f91bcc66438c:double,Sci-Fi_double_VectorAssembler_f91bcc66438c:double,Thriller_double_VectorAssembler_f91bcc66438c:double,War_double_VectorAssembler_f91bcc66438c:double,Western_double_VectorAssembler_f91bcc66438c:double,year_released_double_VectorAssembler_f91bcc66438c:double,rated_released_year_diff_double_VectorAssembler_f91bcc66438c:double,avg(movie_id):double,avg(rating):double,avg(unknown):double,avg(Action):double,avg(Adventure):double,avg(Animation):double,avg(Children's):double,avg(Comedy):double,avg(Crime):double,avg(Documentary):double,avg(Drama):double,avg(Fantasy):double,avg(Film-Noir):double,avg(Horror):double,avg(Musical):double,avg(Mystery):double,avg(Romance):double,avg(Sci-Fi):double,avg(Thriller):double,avg(War):double,avg(Western):double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage26.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage26.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$2.hasNext(WholeStageCodegenExec.scala:638)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:390)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"keep\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:287)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$assemble$1.apply(VectorAssembler.scala:255)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:255)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:144)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$4.apply(VectorAssembler.scala:143)\n\t... 32 more\n"
     ]
    }
   ],
   "source": [
    "model = rf.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_eval = RegressionEvaluator(labelCol=answer_col, metricName='mae')\n",
    "# mae_eval = MulticlassClassificationEvaluator(labelCol=answer_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mae_eval.evaluate(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(labelCol=answer_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nb.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mce = MulticlassClassificationEvaluator(labelCol=answer_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = mce.evaluate(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
