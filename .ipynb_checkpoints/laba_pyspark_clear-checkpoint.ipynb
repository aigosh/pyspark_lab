{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2\n",
    "Выполнили: Елизарова Юлия, Игошин Андрей, Кипаренко Илья, Кириленко Юлия, Клыков Вячеслав, Лепигина Анастасия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing /anaconda3/lib/python3.6/site-packages/sparkmonitor/static -> sparkmonitor\n",
      "- Validating: \u001b[32mOK\u001b[0m\n",
      "\n",
      "    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n",
      "    \n",
      "          jupyter nbextension enable sparkmonitor --user --py\n",
      "    \n",
      "Enabling notebook extension sparkmonitor/module...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "Enabling: sparkmonitor.serverextension\n",
      "- Writing config: /Users/a.y.igoshin/.jupyter\n",
      "    - Validating...\n",
      "      sparkmonitor.serverextension  \u001b[32mOK\u001b[0m\n",
      "/bin/sh: python_path: command not found\n"
     ]
    }
   ],
   "source": [
    "import sparkmonitor\n",
    "!jupyter nbextension install sparkmonitor --py --user --symlink \n",
    "!jupyter nbextension enable sparkmonitor --py --user            \n",
    "!jupyter serverextension enable --py --user sparkmonitor\n",
    "!python_path = !ipython profile locate default\n",
    "!ipython profile create && echo \"c.InteractiveShellApp.extensions.append('sparkmonitor.kernelextension')\" >>  $(ipython profile locate default)/ipython_kernel_config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext.getOrCreate(conf=conf) #Start the spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('MovieRatingsProject').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|           _c0|\n",
      "+--------------+\n",
      "|     943 users|\n",
      "|    1682 items|\n",
      "|100000 ratings|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = spark.read.csv('ml-100k/u.info',inferSchema=True,sep='\\t')\n",
    "info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет содержит 100 000 оценок 934 пользователями 1682 фильмов. Каждый пользователь оценил не менее 20 фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+---------+\n",
      "|user_id|movie_id|rating|timestamp|\n",
      "+-------+--------+------+---------+\n",
      "|    196|     242|     3|881250949|\n",
      "|    186|     302|     3|891717742|\n",
      "|     22|     377|     1|878887116|\n",
      "|    244|      51|     2|880606923|\n",
      "|    166|     346|     1|886397596|\n",
      "|    298|     474|     4|884182806|\n",
      "|    115|     265|     2|881171488|\n",
      "|    253|     465|     5|891628467|\n",
      "|    305|     451|     3|886324817|\n",
      "|      6|      86|     3|883603013|\n",
      "|     62|     257|     2|879372434|\n",
      "|    286|    1014|     5|879781125|\n",
      "|    200|     222|     5|876042340|\n",
      "|    210|      40|     3|891035994|\n",
      "|    224|      29|     3|888104457|\n",
      "|    303|     785|     3|879485318|\n",
      "|    122|     387|     5|879270459|\n",
      "|    194|     274|     2|879539794|\n",
      "|    291|    1042|     4|874834944|\n",
      "|    234|    1184|     2|892079237|\n",
      "+-------+--------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('ml-100k/u.data',inferSchema=True,sep='\\t')\n",
    "data = data.withColumnRenamed('_c0','user_id').withColumnRenamed('_c1','movie_id').withColumnRenamed('_c2','rating').withColumnRenamed('_c3','timestamp')\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация о каждом фильме включает в себя название, даты выхода в прокат и появления в магазинах, ссылку на IMDB и жанр. Причем один фильм может быть отнесен к нескольким жанрам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------------+------------------+--------------------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "| id|         movie_title|release_date|video_release_date|            IMDb_URL|unknown|Action|Adventure|Animation|Children's|Comedy|Crime|Documentary|Drama|Fantasy|Film-Noir|Horror|Musical|Mystery|Romance|Sci-Fi|Thriller|War|Western|\n",
      "+---+--------------------+------------+------------------+--------------------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "|  1|    Toy Story (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        1|         1|     1|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|  2|    GoldenEye (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|\n",
      "|  3|   Four Rooms (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|\n",
      "|  4|   Get Shorty (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     1|        0|        0|         0|     1|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|  5|      Copycat (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    1|          0|    1|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|\n",
      "|  6|Shanghai Triad (Y...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|  7|Twelve Monkeys (1...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     1|       0|  0|      0|\n",
      "|  8|         Babe (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         1|     1|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|  9|Dead Man Walking ...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "| 10|  Richard III (1995)| 22-Jan-1996|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  1|      0|\n",
      "| 11|Seven (Se7en) (1995)| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    1|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|\n",
      "| 12|Usual Suspects, T...| 14-Aug-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    1|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|\n",
      "| 13|Mighty Aphrodite ...| 30-Oct-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     1|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "| 14|  Postino, Il (1994)| 01-Jan-1994|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      1|     0|       0|  0|      0|\n",
      "| 15|Mr. Holland's Opu...| 29-Jan-1996|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "| 16|French Twist (Gaz...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     1|    0|          0|    0|      0|        0|     0|      0|      0|      1|     0|       0|  0|      0|\n",
      "| 17|From Dusk Till Da...| 05-Feb-1996|              null|http://us.imdb.co...|      0|     1|        0|        0|         0|     1|    1|          0|    0|      0|        0|     1|      0|      0|      0|     0|       1|  0|      0|\n",
      "| 18|White Balloon, Th...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "| 19|Antonia's Line (1...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "| 20|Angels and Insect...| 01-Jan-1995|              null|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    1|      0|        0|     0|      0|      0|      1|     0|       0|  0|      0|\n",
      "+---+--------------------+------------+------------------+--------------------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = spark.read.csv('ml-100k/u.item', inferSchema=True, sep='|')\n",
    "names = ['id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "for i in range(len(names)):\n",
    "    movies = movies.withColumnRenamed('_c'+str(i), names[i])\n",
    "movies.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация о каждом пользователе включает в себя возраст, пол, профессию и почтовый индекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+-------------+--------+\n",
      "| id|age|gender|   occupation|zip_code|\n",
      "+---+---+------+-------------+--------+\n",
      "|  1| 24|     M|   technician|   85711|\n",
      "|  2| 53|     F|        other|   94043|\n",
      "|  3| 23|     M|       writer|   32067|\n",
      "|  4| 24|     M|   technician|   43537|\n",
      "|  5| 33|     F|        other|   15213|\n",
      "|  6| 42|     M|    executive|   98101|\n",
      "|  7| 57|     M|administrator|   91344|\n",
      "|  8| 36|     M|administrator|   05201|\n",
      "|  9| 29|     M|      student|   01002|\n",
      "| 10| 53|     M|       lawyer|   90703|\n",
      "| 11| 39|     F|        other|   30329|\n",
      "| 12| 28|     F|        other|   06405|\n",
      "| 13| 47|     M|     educator|   29206|\n",
      "| 14| 45|     M|    scientist|   55106|\n",
      "| 15| 49|     F|     educator|   97301|\n",
      "| 16| 21|     M|entertainment|   10309|\n",
      "| 17| 30|     M|   programmer|   06355|\n",
      "| 18| 35|     F|        other|   37212|\n",
      "| 19| 40|     M|    librarian|   02138|\n",
      "| 20| 42|     F|    homemaker|   95660|\n",
      "+---+---+------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = spark.read.csv('ml-100k/u.user', inferSchema=True, sep='|')\n",
    "names = ['id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "for i in range(len(names)):\n",
    "    users = users.withColumnRenamed('_c'+str(i), names[i])\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения целостного датасета было принято решение собрать датафреймы с оценками и информацией о фильмах и пользователях в один."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+---+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "|user_id|movie_id|rating|age|gender|occupation|unknown|Action|Adventure|Animation|Children's|Comedy|Crime|Documentary|Drama|Fantasy|Film-Noir|Horror|Musical|Mystery|Romance|Sci-Fi|Thriller|War|Western|\n",
      "+-------+--------+------+---+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "|    251|     148|     2| 28|     M|    doctor|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    580|     148|     4| 16|     M|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    633|     148|     1| 35|     M|programmer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    642|     148|     5| 18|     F|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    406|     148|     3| 52|     M|  educator|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|     26|     148|     3| 49|     M|  engineer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|     27|     148|     3| 40|     F| librarian|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    332|     148|     5| 20|     M|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|     44|     148|     4| 26|     M|technician|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    271|     148|     3| 51|     M|  engineer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    606|     148|     3| 28|     M|programmer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    916|     148|     2| 27|     M|  engineer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    236|     148|     4| 44|     F|    writer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    602|     148|     4| 47|     F|     other|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    663|     148|     4| 26|     M|     other|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    222|     148|     2| 29|     M|programmer|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    601|     148|     3| 19|     F|    artist|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    330|     148|     4| 35|     F|  educator|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    372|     148|     5| 25|     F|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    727|     148|     2| 25|     M|   student|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "+-------+--------+------+---+------+----------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = data.join(users, data.user_id == users.id, 'outer').drop('zip_code', 'timestamp')\n",
    "joined_df = joined_df.join(movies, joined_df.movie_id == movies.id, 'outer').drop('movie_title', 'release_date', 'video_release_date', 'IMDb_URL', 'id')\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категориальные значения (профессия, пол) были оформлены при помощи one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+--------------+------------------+\n",
      "|user_id|movie_id|rating|unknown|Action|Adventure|Animation|Children's|Comedy|Crime|Documentary|Drama|Fantasy|Film-Noir|Horror|Musical|Mystery|Romance|Sci-Fi|Thriller|War|Western|gender_feature|occupation_feature|\n",
      "+-------+--------+------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+--------------+------------------+\n",
      "|    251|     148|     2|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|   (20,[19],[1.0])|\n",
      "|    580|     148|     4|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[0],[1.0])|\n",
      "|    633|     148|     1|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[4],[1.0])|\n",
      "|    642|     148|     5|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|     (1,[],[])|    (20,[0],[1.0])|\n",
      "|    406|     148|     3|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[2],[1.0])|\n",
      "|     26|     148|     3|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[3],[1.0])|\n",
      "|     27|     148|     3|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|     (1,[],[])|    (20,[7],[1.0])|\n",
      "|    332|     148|     5|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[0],[1.0])|\n",
      "|     44|     148|     4|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[8],[1.0])|\n",
      "|    271|     148|     3|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[3],[1.0])|\n",
      "|    606|     148|     3|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[4],[1.0])|\n",
      "|    916|     148|     2|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[3],[1.0])|\n",
      "|    236|     148|     4|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|     (1,[],[])|    (20,[6],[1.0])|\n",
      "|    602|     148|     4|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|     (1,[],[])|    (20,[1],[1.0])|\n",
      "|    663|     148|     4|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[1],[1.0])|\n",
      "|    222|     148|     2|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[4],[1.0])|\n",
      "|    601|     148|     3|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|     (1,[],[])|   (20,[11],[1.0])|\n",
      "|    330|     148|     4|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|     (1,[],[])|    (20,[2],[1.0])|\n",
      "|    372|     148|     5|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|     (1,[],[])|    (20,[0],[1.0])|\n",
      "|    727|     148|     2|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0| (1,[0],[1.0])|    (20,[0],[1.0])|\n",
      "+-------+--------+------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"gender\", outputCol=\"indexed_gender\", handleInvalid='error')\n",
    "model = stringIndexer.fit(joined_df)\n",
    "joined_df = model.transform(joined_df)\n",
    "encoder = OneHotEncoder(inputCol=\"indexed_gender\", outputCol=\"gender_feature\")\n",
    "joined_df = encoder.transform(joined_df)\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"occupation\", outputCol=\"indexed_occupation\", handleInvalid='error')\n",
    "model = stringIndexer.fit(joined_df)\n",
    "joined_df = model.transform(joined_df)\n",
    "encoder = OneHotEncoder(inputCol=\"indexed_occupation\", outputCol=\"occupation_feature\")\n",
    "joined_df = encoder.transform(joined_df)\n",
    "\n",
    "# mmScaler = MinMaxScaler(inputCol=\"age\", outputCol=\"scaled_age\")\n",
    "# model = mmScaler.fit(joined_df)\n",
    "# model.transform(joined_df)\n",
    "\n",
    "joined_df = joined_df.drop(\"gender\", \"indexed_gender\", \"occupation\", \"indexed_occupation\", \"age\")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import random\n",
    "\n",
    "user_numbers = random.sample(range(1, 934), 50)\n",
    "predicted = []\n",
    "real = []\n",
    "\n",
    "genres = ['Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "for user_number in user_numbers:\n",
    "    user = joined_df.filter(joined_df.user_id == user_number).collect()\n",
    "    coefs = {'Action':[], 'Adventure':[], 'Animation':[], \"Children's\":[], 'Comedy':[], 'Crime':[], 'Documentary':[], 'Drama':[], 'Fantasy':[], 'Film-Noir':[], 'Horror':[], 'Musical':[], 'Mystery':[], 'Romance':[], 'Sci-Fi':[], 'Thriller':[], 'War':[], 'Western':[]}\n",
    "    for i in range(len(user)):\n",
    "        for genre in genres:\n",
    "            if user[i][genre] == 1:\n",
    "                coefs[genre].append(user[i].rating)\n",
    "    #get coefs for particular user\n",
    "    for genre in genres:\n",
    "        coefs[genre] = np.mean(coefs[genre])\n",
    "    movie_number = user[0].movie_id\n",
    "    movie_info = movies.filter(movies.id == movie_number).collect()\n",
    "    \n",
    "    prediction = []\n",
    "    for genre in genres:\n",
    "        if movie_info[0][genre] == 1:\n",
    "            prediction.append(coefs[genre])\n",
    "    p = np.mean(prediction)\n",
    "    r = user[0].rating\n",
    "    print('predicted', p, round(p), 'real', r)\n",
    "    predicted.append(p)\n",
    "    real.append(r)\n",
    "    #print(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae = 0\n",
    "# mae_rel = 0\n",
    "# for i in range(len(predicted)):\n",
    "#     mae += abs(predicted[i] - real[i])\n",
    "#     mae_rel += abs(predicted[i] - real[i])/real[i]\n",
    "# mae = mae/len(predicted)\n",
    "# mae_rel = mae_rel/len(predicted)\n",
    "# print(mae, mae_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Path does not exist: file:/Users/a.y.igoshin/repos/pyspark_lab/mycsv.csv;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o231.csv.\n: org.apache.spark.sql.AnalysisException: Path does not exist: file:/Users/a.y.igoshin/repos/pyspark_lab/mycsv.csv;\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:558)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:355)\n\tat org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:617)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8931ae6fe2a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0musers_pref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mycsv.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0musers_pref_sort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musers_pref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Path does not exist: file:/Users/a.y.igoshin/repos/pyspark_lab/mycsv.csv;'"
     ]
    }
   ],
   "source": [
    "users_pref = spark.read.csv('mycsv.csv', inferSchema=True, sep=',', header='true')\n",
    "\n",
    "users_pref_sort = users_pref.sort(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 128\n",
    "genres = ['Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "list_of_user_pref = []\n",
    "pref = users_pref_sort.filter(users_pref_sort.user_id == user_id).collect()\n",
    "print(\"PREFERENCES\", pref)\n",
    "watched_movies = []\n",
    "user_watched = data.filter(data.user_id == user_id).collect()\n",
    "for i in range(len(user_watched)):\n",
    "    watched_movies.append(user_watched[i]['movie_id'])\n",
    "print(\"WATCHED\", watched_movies)\n",
    "movies_list = movies.filter(movies.id == movies.id).collect()\n",
    "marks = {}\n",
    "#print(movies_list)\n",
    "for i in range(len(movies_list)):\n",
    "    if movies_list[i]['id'] not in user_watched:\n",
    "        mark = []\n",
    "        for genre in genres:\n",
    "            if pref[0]['avg('+genre+')'] != None and movies_list[i][genre] != None and movies_list[i][genre] == 1:\n",
    "                mark.append(pref[0]['avg('+genre+')']*movies_list[i][genre])\n",
    "        marks[movies_list[i]['id']] = np.mean(mark)\n",
    "sorted_by_value = sorted(marks.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(\"BEST 100\", sorted_by_value[:100])\n",
    "recommendation = [i[0] for i in sorted_by_value if i[1] == 5.0]\n",
    "print(\"RECOMMENDED\", recommendation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
